{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "78380740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# === Step 0: Import Libraries ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models & Pickle for saving\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"✅ Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4245c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully.\n",
      "\n",
      "=== INITIAL HEAD ===\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2014-09-17  465.864014  468.174011  452.421997  457.334015  457.334015   \n",
      "1  2014-09-18  456.859985  456.859985  413.104004  424.440002  424.440002   \n",
      "2  2014-09-19  424.102997  427.834991  384.532013  394.795990  394.795990   \n",
      "3  2014-09-20  394.673004  423.295990  389.882996  408.903992  408.903992   \n",
      "4  2014-09-21  408.084991  412.425995  393.181000  398.821014  398.821014   \n",
      "\n",
      "     Volume  \n",
      "0  21056800  \n",
      "1  34483200  \n",
      "2  37919700  \n",
      "3  36863600  \n",
      "4  26580100  \n"
     ]
    }
   ],
   "source": [
    "# === Step 1: Load Dataset ===\n",
    "CSV_PATH = \"./Dataset/Bitcoin - Dataset.csv\"  # Change path if needed\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"✅ Dataset loaded successfully.\\n\")\n",
    "print(\"=== INITIAL HEAD ===\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "af7aeb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATAFRAME INFO ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2713 entries, 0 to 2712\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       2713 non-null   object \n",
      " 1   Open       2713 non-null   float64\n",
      " 2   High       2713 non-null   float64\n",
      " 3   Low        2713 non-null   float64\n",
      " 4   Close      2713 non-null   float64\n",
      " 5   Adj Close  2713 non-null   float64\n",
      " 6   Volume     2713 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 148.5+ KB\n",
      "None\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "Date         0\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "\n",
      "=== STATISTICAL SUMMARY ===\n",
      "               Open          High           Low         Close     Adj Close  \\\n",
      "count   2713.000000   2713.000000   2713.000000   2713.000000   2713.000000   \n",
      "mean   11311.041069  11614.292482  10975.555057  11323.914637  11323.914637   \n",
      "std    16106.428891  16537.390649  15608.572560  16110.365010  16110.365010   \n",
      "min      176.897003    211.731003    171.509995    178.102997    178.102997   \n",
      "25%      606.396973    609.260986    604.109985    606.718994    606.718994   \n",
      "50%     6301.569824   6434.617676   6214.220215   6317.609863   6317.609863   \n",
      "75%    10452.399414  10762.644531  10202.387695  10462.259766  10462.259766   \n",
      "max    67549.734375  68789.625000  66382.062500  67566.828125  67566.828125   \n",
      "\n",
      "             Volume  \n",
      "count  2.713000e+03  \n",
      "mean   1.470462e+10  \n",
      "std    2.001627e+10  \n",
      "min    5.914570e+06  \n",
      "25%    7.991080e+07  \n",
      "50%    5.098183e+09  \n",
      "75%    2.456992e+10  \n",
      "max    3.509679e+11  \n"
     ]
    }
   ],
   "source": [
    "# === Step 2: Initial Data Exploration ===\n",
    "print(\"\\n=== DATAFRAME INFO ===\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cbdf8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NUMERIC-LIKE COLUMNS DETECTED ===\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Automatically detect numeric-like columns ===\n",
    "# Keep only columns that contain numbers (ignore text/date)\n",
    "numeric_like_cols = [\n",
    "    col for col in df.columns\n",
    "    if df[col].astype(str).str.replace(r\"[^0-9.\\-]\", \"\", regex=True).str.strip().ne(\"\").any()\n",
    "]\n",
    "\n",
    "print(\"\\n=== NUMERIC-LIKE COLUMNS DETECTED ===\")\n",
    "print(numeric_like_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4ff55fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Numeric-like columns converted to numeric types.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Convert them safely to numeric ===\n",
    "for col in numeric_like_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "print(\"\\n✅ Numeric-like columns converted to numeric types.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "06b1d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Missing values handled.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Handle missing values ===\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "print(\"\\n✅ Missing values handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c521d577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped duplicates:    (2713, 7) → (2713, 7)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Remove duplicates ===\n",
    "before = df.shape\n",
    "df = df.drop_duplicates()\n",
    "after = df.shape\n",
    "print(f\"\\nDropped duplicates:    {before} → {after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4d7db5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Engineered features created.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Create engineered features (if columns exist) ===\n",
    "if set([\"High\", \"Low\"]).issubset(df.columns):\n",
    "    df[\"Price_Range\"] = df[\"High\"] - df[\"Low\"]\n",
    "    df[\"Avg_Price\"] = (df[\"High\"] + df[\"Low\"]) / 2\n",
    "if set([\"Open\", \"Close\"]).issubset(df.columns):\n",
    "    df[\"Day_Return\"] = df[\"Close\"] - df[\"Open\"]\n",
    "if set([\"High\", \"Low\", \"Open\"]).issubset(df.columns):\n",
    "    df[\"Volatility\"] = np.where(df[\"Open\"] != 0, (df[\"High\"] - df[\"Low\"]) / df[\"Open\"], 0)\n",
    "print(\"\\n✅ Engineered features created.\")\n",
    "\n",
    "# Optional if \"Turnover\" or \"Trade Quantity\" exists\n",
    "if \"Turnover (Lacs)\" in df.columns and \"Total Trade Quantity\" in df.columns:\n",
    "    df[\"Turnover_per_Trade\"] = df[\"Turnover (Lacs)\"] / (df[\"Total Trade Quantity\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2d770713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Feature scaling completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Feature Scaling ===\n",
    "scale_cols = [\"Open\", \"High\", \"Low\", \"Price_Range\", \"Avg_Price\", \"Day_Return\", \"Volatility\"]\n",
    "scaler = StandardScaler()\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "print(\"\\n✅ Feature scaling completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cee70f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Scaler saved to models/bitcoin_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save scaler\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(scaler, \"models/bitcoin_scaler.pkl\")\n",
    "print(\"\\n✅ Scaler saved to models/bitcoin_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a8c4bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Training columns saved to models/bitcoin_train_columns.json\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Save training columns ===\n",
    "TRAIN_COLUMNS = df.drop(columns=[\"Close\", \"Date\"]).columns.tolist()\n",
    "json.dump(TRAIN_COLUMNS, open(\"models/bitcoin_train_columns.json\", \"w\"))\n",
    "print(\"\\n✅ Training columns saved to models/bitcoin_train_columns.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b7642bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL HEAD ===\n",
      "   Date      Open      High       Low       Close   Adj Close    Volume  \\\n",
      "0   NaN -0.673469 -0.674119 -0.674314  457.334015  457.334015  21056800   \n",
      "1   NaN -0.674028 -0.674804 -0.676833  424.440002  424.440002  34483200   \n",
      "2   NaN -0.676062 -0.676559 -0.678664  394.795990  394.795990  37919700   \n",
      "3   NaN -0.677890 -0.676833 -0.678321  408.903992  408.903992  36863600   \n",
      "4   NaN -0.677057 -0.677491 -0.678110  398.821014  398.821014  26580100   \n",
      "\n",
      "   Price_Range  Avg_Price  Day_Return  Volatility  \n",
      "0    -0.535231  -0.674374   -0.027585   -0.330762  \n",
      "1    -0.511172  -0.675950   -0.058374    1.247730  \n",
      "2    -0.511561  -0.677743   -0.054362    1.408970  \n",
      "3    -0.520058  -0.677717    0.001749    0.964565  \n",
      "4    -0.532230  -0.677953   -0.028531    0.009244  \n",
      "\n",
      "=== FINAL INFO ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2713 entries, 0 to 2712\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Date         0 non-null      float64\n",
      " 1   Open         2713 non-null   float64\n",
      " 2   High         2713 non-null   float64\n",
      " 3   Low          2713 non-null   float64\n",
      " 4   Close        2713 non-null   float64\n",
      " 5   Adj Close    2713 non-null   float64\n",
      " 6   Volume       2713 non-null   int64  \n",
      " 7   Price_Range  2713 non-null   float64\n",
      " 8   Avg_Price    2713 non-null   float64\n",
      " 9   Day_Return   2713 non-null   float64\n",
      " 10  Volatility   2713 non-null   float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 233.3 KB\n",
      "None\n",
      "\n",
      "=== FINAL MISSING VALUES ===\n",
      "Date           2713\n",
      "Open              0\n",
      "High              0\n",
      "Low               0\n",
      "Close             0\n",
      "Adj Close         0\n",
      "Volume            0\n",
      "Price_Range       0\n",
      "Avg_Price         0\n",
      "Day_Return        0\n",
      "Volatility        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 11: Final Snapshot ===\n",
    "print(\"\\n=== FINAL HEAD ===\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n=== FINAL INFO ===\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n=== FINAL MISSING VALUES ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "41c22f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Cleaned dataset saved to ./Dataset/Bitcoin-Cleaned-Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Save Cleaned Dataset ===\n",
    "os.makedirs(\"Dataset\", exist_ok=True)\n",
    "OUT_PATH = \"./Dataset/Bitcoin-Cleaned-Dataset.csv\"\n",
    "df.to_csv(OUT_PATH, index=False)\n",
    "print(f\"\\n✅ Cleaned dataset saved to {OUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
